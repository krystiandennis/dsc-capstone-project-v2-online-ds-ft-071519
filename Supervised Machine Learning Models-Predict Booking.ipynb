{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Libraries Imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from cf_matrix import make_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('All Libraries Imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets for all six classes of tweets are imported for modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_pickle('all_data.pkl')\n",
    "all_data.reset_index(inplace=True)\n",
    "all_data.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_TextBlob</th>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Tweet_Strings</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Luxury</td>\n",
       "      <td>2019-12-13 14:47:03</td>\n",
       "      <td>[polo, anyone, world, snow, polo, championship...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>polo anyone world snow polo championship held ...</td>\n",
       "      <td>Polo anyone?\\r\\n#StRegis World Snow #Polo Cham...</td>\n",
       "      <td>[polo, anyone, world, snow, polo, championship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luxury</td>\n",
       "      <td>2019-12-13 13:05:34</td>\n",
       "      <td>[fantastic, night, celebrating, th, anniversary]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.9</td>\n",
       "      <td>fantastic night celebrating th anniversary</td>\n",
       "      <td>Fantastic night at the @TheStRegisMC celebrati...</td>\n",
       "      <td>[fantastic, night, celebrating, th, anniversary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury</td>\n",
       "      <td>2019-12-13 09:16:46</td>\n",
       "      <td>[exceptional, tropical, sunshine, ensures, ult...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>0.8</td>\n",
       "      <td>exceptional tropical sunshine ensures ultimate...</td>\n",
       "      <td>It's the exceptional tropical sunshine that en...</td>\n",
       "      <td>[exceptional, tropical, sunshine, ensures, ult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Luxury</td>\n",
       "      <td>2019-12-13 04:05:43</td>\n",
       "      <td>[birthday, sagittarius, aspen, ilovemylife, ha...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>birthday sagittarius aspen ilovemylife happybi...</td>\n",
       "      <td>This is 38. üéÇüèπüëÄüò¨üç∫üç∞üí© @stregisaspen #birthday #üéÇ...</td>\n",
       "      <td>[birthday, sagittarius, aspen, ilovemylife, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Luxury</td>\n",
       "      <td>2019-12-13 00:14:04</td>\n",
       "      <td>[stunning, overwater, bar, see, today, called,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>0.5</td>\n",
       "      <td>stunning overwater bar see today called whale ...</td>\n",
       "      <td>Stunning overwater bar you will see today! It'...</td>\n",
       "      <td>[stunning, overwater, bar, see, today, called,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class           Created At  \\\n",
       "0  Luxury  2019-12-13 14:47:03   \n",
       "1  Luxury  2019-12-13 13:05:34   \n",
       "2  Luxury  2019-12-13 09:16:46   \n",
       "3  Luxury  2019-12-13 04:05:43   \n",
       "4  Luxury  2019-12-13 00:14:04   \n",
       "\n",
       "                                          Lemmatized  Sentiment  \\\n",
       "0  [polo, anyone, world, snow, polo, championship...          1   \n",
       "1   [fantastic, night, celebrating, th, anniversary]          1   \n",
       "2  [exceptional, tropical, sunshine, ensures, ult...          1   \n",
       "3  [birthday, sagittarius, aspen, ilovemylife, ha...          1   \n",
       "4  [stunning, overwater, bar, see, today, called,...          1   \n",
       "\n",
       "   Sentiment_TextBlob  Sentiment_VADER  Subjectivity  \\\n",
       "0            0.000000           0.4404           0.0   \n",
       "1            0.400000           0.8074           0.9   \n",
       "2            0.413333           0.8689           0.8   \n",
       "3            0.000000           0.0000           0.0   \n",
       "4            0.341667           0.9359           0.5   \n",
       "\n",
       "                                       Tweet_Strings  \\\n",
       "0  polo anyone world snow polo championship held ...   \n",
       "1         fantastic night celebrating th anniversary   \n",
       "2  exceptional tropical sunshine ensures ultimate...   \n",
       "3  birthday sagittarius aspen ilovemylife happybi...   \n",
       "4  stunning overwater bar see today called whale ...   \n",
       "\n",
       "                                              Tweets  \\\n",
       "0  Polo anyone?\\r\\n#StRegis World Snow #Polo Cham...   \n",
       "1  Fantastic night at the @TheStRegisMC celebrati...   \n",
       "2  It's the exceptional tropical sunshine that en...   \n",
       "3  This is 38. üéÇüèπüëÄüò¨üç∫üç∞üí© @stregisaspen #birthday #üéÇ...   \n",
       "4  Stunning overwater bar you will see today! It'...   \n",
       "\n",
       "                                      cleaned_tweets  \n",
       "0  [polo, anyone, world, snow, polo, championship...  \n",
       "1   [fantastic, night, celebrating, th, anniversary]  \n",
       "2  [exceptional, tropical, sunshine, ensures, ult...  \n",
       "3  [birthday, sagittarius, aspen, ilovemylife, ha...  \n",
       "4  [stunning, overwater, bar, see, today, called,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19936 entries, 0 to 19935\n",
      "Data columns (total 10 columns):\n",
      "Class                 19936 non-null object\n",
      "Created At            19936 non-null object\n",
      "Lemmatized            19936 non-null object\n",
      "Sentiment             19936 non-null int64\n",
      "Sentiment_TextBlob    19936 non-null float64\n",
      "Sentiment_VADER       19936 non-null float64\n",
      "Subjectivity          19936 non-null float64\n",
      "Tweet_Strings         19936 non-null object\n",
      "Tweets                19936 non-null object\n",
      "cleaned_tweets        19936 non-null object\n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_TextBlob</th>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19936.00</td>\n",
       "      <td>19936.00</td>\n",
       "      <td>19936.00</td>\n",
       "      <td>19936.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment  Sentiment_TextBlob  Sentiment_VADER  Subjectivity\n",
       "count   19936.00            19936.00         19936.00      19936.00\n",
       "mean        0.87                0.18             0.29          0.35\n",
       "std         0.33                0.31             0.43          0.32\n",
       "min         0.00               -1.00            -0.97          0.00\n",
       "25%         1.00                0.00             0.00          0.00\n",
       "50%         1.00                0.05             0.36          0.35\n",
       "75%         1.00                0.35             0.64          0.60\n",
       "max         1.00                1.00             0.99          1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(all_data.head())\n",
    "display(all_data.info())\n",
    "display(round(all_data.describe(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweets</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tweet_Strings</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subjectivity</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment_VADER</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment_TextBlob</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lemmatized</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Created At</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total  Percent\n",
       "cleaned_tweets          0      0.0\n",
       "Tweets                  0      0.0\n",
       "Tweet_Strings           0      0.0\n",
       "Subjectivity            0      0.0\n",
       "Sentiment_VADER         0      0.0\n",
       "Sentiment_TextBlob      0      0.0\n",
       "Sentiment               0      0.0\n",
       "Lemmatized              0      0.0\n",
       "Created At              0      0.0\n",
       "Class                   0      0.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing data\n",
    "total = all_data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (all_data.isnull().sum()/all_data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are used to create models and gather metrics on the classification models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_best_model(classifier, param_grid, dataset):\n",
    "    \"\"\"\n",
    "    This function will use a gridsearch to fit a model using the classifier and parameter\n",
    "    grid provided. It will return a dictionary containng the model along with test results.\n",
    "    \n",
    "    INPUTS:\n",
    "    classifier                 = The classifier being fit.\n",
    "    datasets    = Tuple containing train and test data in the format (X_train,X_test,y_train,y_test)\n",
    "    param_grid          = The parameters to use for gridsearch fitting of the classifier.\n",
    "    \n",
    "    RETURNS:\n",
    "    Dataframe with the following keys:\n",
    "    Dataset = The dataset used to create the best model.\n",
    "    Best parameters = The best model parameters used.\n",
    "    Best Training Score  = The best accuracy score of the model on the training data.\n",
    "    Test score  = The accuracy of the model on the test data.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for data in datasets:\n",
    "    \n",
    "        gs = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=5, scoring='accuracy', verbose = 5)\n",
    "        gs.fit(data['X_train'], data['y_train'])\n",
    "\n",
    "        model_params = gs.best_params_\n",
    "        model_score = round(gs.best_score_,2)\n",
    "        y_pred_test  = gs.predict(data['X_test'])\n",
    "\n",
    "        accuracy_test  = round(accuracy_score(data['y_test'],y_pred_test),4)\n",
    "        \n",
    "        results.append({'Dataset':data['name'], 'Best Training Score': model_score, 'Test Score': accuracy_test, 'Best Parameters': model_params})\n",
    "        \n",
    "    pd.set_option('display.max_colwidth', 2000)\n",
    "    df = pd.DataFrame(results)\n",
    "    df.sort_values(by=['Test Score','Best Training Score'], inplace=True, ascending=False)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = len(X_train.columns)\n",
    "    plt.figure(figsize=(14,10))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importances(model):\n",
    "    n_features = tf_idf_X_train.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), tf_idf_df_train.columns.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    lw = 2\n",
    "    auc = round(auc(fpr, tpr),2)\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='AUC = %0.2f' % auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.yticks([i/20.0 for i in range(21)])\n",
    "    plt.xticks([i/20.0 for i in range(21)])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Datasets into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that the models are not overfitted, the data is split into one set for testing models and another set for validating the model. The train_test_split() method is used to create datasets for all six classes of tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data['Tweet_Strings']\n",
    "y = all_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most algorithms cannot interpret text, the tweets are converted into an array of numbers. This method is called vectoriztations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "bow_X_train = count_vec.fit_transform(X_train).toarray()\n",
    "bow_X_test = count_vec.transform(X_test)\n",
    "bow_df_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF_IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_idf_X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "tf_idf_X_test = vectorizer.transform(X_test)\n",
    "tf_idf_df_train = pd.DataFrame(tf_idf_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {'name': 'tf_idf','X_train': tf_idf_X_train, 'y_train':y_train, 'X_test': tf_idf_X_test, 'y_test': y_test}\n",
    "bag_of_words = {'name': 'bag_of_words','X_train': bow_X_train, 'y_train': y_train, 'X_test': bow_X_test, 'y_test':y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [tf_idf, bag_of_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three classification models have been chosen:\n",
    "\n",
    "- Multinomial Na√Øve Bayes - This version of Naive Bayes, created specially for text, explicitly models the word counts and adjusts the underlying calculations.\n",
    "\n",
    "- Logistic Regression - Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.\n",
    "\n",
    "- Random Forest - Random Forest algorithm is an ensemble of Decision Trees. Random forests creates decision trees on randomly selected data samples, gets prediction from each tree and selects the best solution by means of voting.\n",
    "\n",
    "GridsearchCV will be used to tune the models by finding the best perfoming parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = MultinomialNB()\n",
    "naive_param_grid = {'alpha': [1, 0.8, 0.5, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "                    'fit_prior': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_best_model(naive, naive_param_grid, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model Parameters - Multinomial Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model constructed with best parameters for Multinomial Na√Øve Bayes.\n",
    "\n",
    "* **Alpha**: 0.1\n",
    "* **Fit_Prior**: True\n",
    "* **Dataset**: TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB(alpha = 0.1, fit_prior = True)\n",
    "\n",
    "nb.fit(tf_idf_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_preds = nb.predict(tf_idf_X_train)\n",
    "nb_preds = nb.predict(tf_idf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Multinomial Na√Øve Bayes\n",
      "\n",
      "[[  537   127     0   279     0     0]\n",
      " [   21  2477     0   320    30     0]\n",
      " [    0    20   504   309     0     0]\n",
      " [    2   149    25 10561     4     1]\n",
      " [   24   141     0   120   224     0]\n",
      " [    0     1     1    58     0    13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Booking.com       0.92      0.57      0.70       943\n",
      "     Expedia       0.85      0.87      0.86      2848\n",
      "      Luxury       0.95      0.61      0.74       833\n",
      "     Premium       0.91      0.98      0.94     10742\n",
      "   Priceline       0.87      0.44      0.58       509\n",
      "      Select       0.93      0.18      0.30        73\n",
      "\n",
      "    accuracy                           0.90     15948\n",
      "   macro avg       0.90      0.61      0.69     15948\n",
      "weighted avg       0.90      0.90      0.89     15948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training Data - Multinomial Na√Øve Bayes\\n')\n",
    "print(confusion_matrix(y_train, nb_train_preds))\n",
    "print(classification_report(y_train, nb_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data - Multinomial Na√Øve Bayes\n",
      "\n",
      "[[  69   50    0   97    0    0]\n",
      " [   9  503    0  210    8    0]\n",
      " [   0    7   42  133    0    0]\n",
      " [   4   80    9 2640    2    0]\n",
      " [   5   36    0   39   29    0]\n",
      " [   0    1    0   15    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Booking.com       0.79      0.32      0.46       216\n",
      "     Expedia       0.74      0.69      0.71       730\n",
      "      Luxury       0.82      0.23      0.36       182\n",
      "     Premium       0.84      0.97      0.90      2735\n",
      "   Priceline       0.74      0.27      0.39       109\n",
      "      Select       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.82      3988\n",
      "   macro avg       0.66      0.41      0.47      3988\n",
      "weighted avg       0.81      0.82      0.80      3988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing Data - Multinomial Na√Øve Bayes\\n')\n",
    "print(confusion_matrix(y_test, nb_preds))\n",
    "print(classification_report(y_test, nb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nb.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nb, 'nb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state = 42, multi_class = 'multinomial')\n",
    "log_param_grid = {'C':[0.01, 0.1, 1, 2, 10],\n",
    "                 'solver':['lbfgs','saga','newton-cg', 'sag'],\n",
    "                 'class_weight': ['balanced', None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_best_model(log_reg, log_param_grid, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model Parameters - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model constructed with best parameters for Multinomial Logistic Regression\n",
    "\n",
    "* **C: 2\n",
    "* **Solver**: Newton-cg\n",
    "* **Class_Weight**: None\n",
    "* **Dataset**: TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C= 2, class_weight= None , solver= 'newton-cg', random_state=42, multi_class = 'multinomial')\n",
    "\n",
    "log_reg.fit(tf_idf_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_preds = log_reg.predict(tf_idf_X_train)\n",
    "log_preds = log_reg.predict(tf_idf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Multinomial Logistic Regression\n",
      "\n",
      "[[  526    92     1   311    13     0]\n",
      " [   19  2410     8   393    18     0]\n",
      " [    2    10   368   453     0     0]\n",
      " [    5    78     9 10648     2     0]\n",
      " [   17   133     2   151   206     0]\n",
      " [    0     0     1    64     1     7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Booking.com       0.92      0.56      0.70       943\n",
      "     Expedia       0.89      0.85      0.87      2848\n",
      "      Luxury       0.95      0.44      0.60       833\n",
      "     Premium       0.89      0.99      0.94     10742\n",
      "   Priceline       0.86      0.40      0.55       509\n",
      "      Select       1.00      0.10      0.17        73\n",
      "\n",
      "    accuracy                           0.89     15948\n",
      "   macro avg       0.92      0.56      0.64     15948\n",
      "weighted avg       0.89      0.89      0.88     15948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training Data - Multinomial Logistic Regression\\n')\n",
    "print(confusion_matrix(y_train, log_train_preds))\n",
    "print(classification_report(y_train, log_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data - Multinomial Logistic Regression\n",
      "\n",
      "[[  86   32    1   93    4    0]\n",
      " [  19  480    0  222    9    0]\n",
      " [   1    9   36  136    0    0]\n",
      " [   3   59    6 2664    3    0]\n",
      " [   6   33    0   41   29    0]\n",
      " [   0    1    0   15    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Booking.com       0.75      0.40      0.52       216\n",
      "     Expedia       0.78      0.66      0.71       730\n",
      "      Luxury       0.84      0.20      0.32       182\n",
      "     Premium       0.84      0.97      0.90      2735\n",
      "   Priceline       0.64      0.27      0.38       109\n",
      "      Select       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.83      3988\n",
      "   macro avg       0.64      0.42      0.47      3988\n",
      "weighted avg       0.82      0.83      0.80      3988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing Data - Multinomial Logistic Regression\\n')\n",
    "print(confusion_matrix(y_test, log_preds))\n",
    "print(classification_report(y_test, log_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_reg.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(log_reg, 'log_reg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)             \n",
    "rf_param_grid = {'n_estimators': [50,75,100,125,150],\n",
    "                 'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [None, 2, 5, 10],\n",
    "              'class_weight': ['balanced', None],\n",
    "                'bootstrap': [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_best_model(rf, rf_param_grid, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model Parameters - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model constructed with best parameters for Random Forest.\n",
    "\n",
    "* **Bootstrap**: True\n",
    "* **Class Weight**: None\n",
    "* **Criterion**: Gini\n",
    "* **Max Depth**: None\n",
    "* **Number of Estimators**: 50\n",
    "* **Dataset**: TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, bootstrap=True, class_weight=None, criterion='gini', max_depth=None, n_estimators=50)\n",
    "\n",
    "rf.fit(tf_idf_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_preds = rf.predict(tf_idf_X_train)\n",
    "rf_preds = rf.predict(tf_idf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - Random Forest\n",
      "\n",
      "[[  888    28     0     5    22     0]\n",
      " [   35  2760     5    18    30     0]\n",
      " [    8     2   795    28     0     0]\n",
      " [   54    17    16 10650     1     4]\n",
      " [   14    24     0     4   467     0]\n",
      " [    0     0     0    12     0    61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Booking.com       0.89      0.94      0.91       943\n",
      "     Expedia       0.97      0.97      0.97      2848\n",
      "      Luxury       0.97      0.95      0.96       833\n",
      "     Premium       0.99      0.99      0.99     10742\n",
      "   Priceline       0.90      0.92      0.91       509\n",
      "      Select       0.94      0.84      0.88        73\n",
      "\n",
      "    accuracy                           0.98     15948\n",
      "   macro avg       0.94      0.93      0.94     15948\n",
      "weighted avg       0.98      0.98      0.98     15948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training Data - Random Forest\\n')\n",
    "print(confusion_matrix(y_train, rf_train_preds))\n",
    "print(classification_report(y_train, rf_train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data - Random Forest\n",
      "\n",
      "[[ 117   34    1   60    4    0]\n",
      " [  53  454    5  206   12    0]\n",
      " [   1   12   51  115    1    2]\n",
      " [  68   68   20 2569    3    7]\n",
      " [  10   45    0   26   28    0]\n",
      " [   0    0    0   13    0    3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Booking.com       0.47      0.54      0.50       216\n",
      "     Expedia       0.74      0.62      0.68       730\n",
      "      Luxury       0.66      0.28      0.39       182\n",
      "     Premium       0.86      0.94      0.90      2735\n",
      "   Priceline       0.58      0.26      0.36       109\n",
      "      Select       0.25      0.19      0.21        16\n",
      "\n",
      "    accuracy                           0.81      3988\n",
      "   macro avg       0.59      0.47      0.51      3988\n",
      "weighted avg       0.80      0.81      0.80      3988\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Testing Data - Random Forest\\n')\n",
    "print(confusion_matrix(y_test, rf_preds))\n",
    "print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rf, 'rf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [nb, rf ,log_reg]\n",
    "model_names = ['Multinomial Na√Øve Bayes','Random Forest','Multinomial Logistic Regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best accuracy: Multinomial Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_pipe = ''\n",
    "for index, val in enumerate(models):\n",
    "    if val.score(tf_idf_X_test, y_test) > best_acc:\n",
    "        best_acc = val.score(tf_idf_X_test, y_test)\n",
    "        best_pipe = val\n",
    "        best_clf = index\n",
    "print('Classifier with best accuracy: %s' % model_names[best_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier with the best accuracy is **Multinomial Logistic Regression** at **83%**. It will be used for interpretation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.21687636 -0.09190841 -0.17157429 ... -0.11389845 -0.03006101\n",
      "  -0.02046255]\n",
      " [-0.72196841  0.29761311  0.44871866 ... -0.04551712 -0.05790089\n",
      "  -0.02768475]\n",
      " [-0.13060844 -0.09007998 -0.0329394  ... -0.02977021 -0.02492691\n",
      "  -0.01993557]\n",
      " [ 1.38385824 -0.01962936 -0.21720199 ...  0.23690397  0.14433794\n",
      "   0.07672821]\n",
      " [-0.29213407 -0.083384   -0.02038606 ... -0.03777292 -0.02750856\n",
      "  -0.00631981]\n",
      " [-0.02227096 -0.01261137 -0.00661694 ... -0.00994527 -0.00394056\n",
      "  -0.00232553]]\n"
     ]
    }
   ],
   "source": [
    "print(log_reg.coef_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle X_test and y_test as binary\n",
    "pickle.dump(X_test, open( \"X_test.pkl\", \"wb\" ))\n",
    "pickle.dump(y_test, open( \"y_test.pkl\", \"wb\" ))\n",
    "pickle.dump(tf_idf_X_test, open(\"tf_idf_X_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gather More Tweets\n",
    "2. Topic Modeling with Latent Dirichlet Allocation(LDA)\n",
    "3. Different Algorithms\n",
    "    * KNN\n",
    "    * XG Boost\n",
    "    * Support Vector Machines\n",
    "    * Neural Networks\n",
    "        -RNN/LSTM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
